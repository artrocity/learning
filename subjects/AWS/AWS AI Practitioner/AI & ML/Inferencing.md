## What is it
- Inferencing is when a model is making predictions on new data
- Real time
	- Computers have to make decisions quickly as data arrives
	- Speed is preferred over accuracy
	- Example:
		- Chatbots
- Batch
	- Large amount of data analyzed at once
	- Used for data analysis
	- Accuracy is valuable, Speed of the results is not a concern

## Inferencing at the Edge
 - Options
	 - Small Language Model
		 - Uses Small language models on the edge device, such as a Raspberry Pi
		 - Very Low Latency
		 - Offline capability
	- LLM
		- More powerful
		- Higher Latency
		- Connected to via a remote server
		- Requires internet access