# What is Generative AI
- A subset of Deep Learning - used to generate new data that is similar to the data it was trained on such as text, images, audio, code, and video
- Generative AI Workflow
	- Unlabeled Data
	- Pre-train to create a Foundational Model
	- Foundational Model can then adapts to a broad range of tasks

# Foundational Model
 - To generate data, we must rely on Foundational Models
 - Foundational models are trained on a wide array of input data
 - Models may cost  tens of millions of dollars to train due to the sheer cpu/gpu usage and extremely large datasets
 - There are a wide selections of Foundation Models from various companies such as:
	 - OpenAI - GPT-4o
	 - Meta
	 - Amazon - Q 
	 - Google - Gemeni / BERT
	 - Anthropic - Claude

# Large Language Models
- Type of AI relying on Foundational Models that are designed to generate coherent human-like text
- Trained on large corpus of text data
- Trained on extremely large datasets
	- Billions of parameters
	- Trained on books, articles, websites, and other textual data
- Can perform language related tasks

# How to use a Generative Language Model
 - We interact with the LLM by giving a prompt
 - Then model then leverages all the existing content it's learned from to generate new content
 - The output from the LLM is **NON-DETERMINISTIC**: Generated text may be different for every user that uses the same prompt
